---
date: "2022-05-23"
title: "Playing Mario directly from latent space"
summary: "In this blogpost I open-source tools for training VAEs on Mario, and playing its levels using an A star agent"
lang: "en"
show: true
imgsrc: "/assets/mario_blogpost/1175.png"
categories:
    - Variational Autoencoder
    - Super Mario Bros
    - PyTorch
---

<Heading aria-label="Jump to title" as="h1" hash="PlayingMario">Playing Mario directly from latent space.</Heading>

[We recently open sourced an implementation of a categorical VAE trained on levels from the classic game Super Mario Bros.](https://github.com/miguelgondu/minimal_VAE_on_Mario) In this blogpost I expand on how it works, and how it can be used to play content directly from latent space. This blogpost covers how the model is defined and how the simulator we provide can be used to automatically extract things like how many jumps were performed, or whether the level is solvable by an artificial agent.

This post assumes you know a little bit about about how Variational Autoencoders work (e.g. what the ELBO loss is), that you know how to use Python up to an intermediate level, and that's it!

<Heading aria-label="Jump to the data" as="h2" hash="TheData">The data: levels from Super Mario Bros</Heading>

In the [Video Game Level Corpus](https://github.com/TheVGLC/TheVGLC) you can find post-processed versions of content for several different games, including Super Mario Bros 1 and 2. These processed levels, in the case of SMB 1, are long text files with 14 rows and $n$ columns. In these files, all sprites are encoded using a unique token: `"-"` represents empty space, `"X"` represents the floor... There are 11 unique sprites in total.

We split them into 14x14 chuncks by rolling a window across all levels. In total, we have 2713 levels saved in `./data/all_levels_onehot.npz` as `(n_sprites=11, height=14, width=14)` arrays. To load them, you can run `np.load(that_path)["levels"]`. Here are three random examples of said levels, visualized using some of the tools provided in the repo:

<p align="center">
  <img src={"/assets/mario_blogpost/example_levels.png"}  width="100%"/>
</p>

<Heading aria-label="Jump to the model" as="h2" hash="TheModel">The model: a categorical VAE</Heading>

We used a simple Variational Autoencoder with multi-layer perceptrons for both the encoder and the decoder. Remember that a Variational Autoencoder models the latent variables $z$ that generate a given piece of content $x$ by proposing a variational distribution $q(z|x)$ (which is usually a multivariate Normal), and approximating the distribution of the data given a latent code $z$ with a distribution $p(x|z)$ that depends on the nature of the data. In our case, we model the distribution of the data using **a categorical distribution**. These two distributions are parametrized using neural networks (the encoder and decoder, respectively).

With [PyTorch Distributions](https://pytorch.org/docs/stable/distributions.html), implementing these distributions is easy! We model the encoder using the following layers:

```python
self.encoder = nn.Sequential(
    nn.Linear(self.input_dim, 512),  # self.input_dim = 14 x 14 x 11
    nn.Tanh(),
    nn.Linear(512, 256),
    nn.Tanh(),
    nn.Linear(256, 128),
    nn.Tanh(),
).to(self.device)
self.enc_mu = nn.Sequential(nn.Linear(128, z_dim)).to(self.device)
self.enc_var = nn.Sequential(nn.Linear(128, z_dim)).to(self.device)
```

That way, when we encode we can return a `Normal` distribution:
```python
def encode(self, x: torch.Tensor) -> Normal:
    # Returns q(z | x) = Normal(mu, sigma)
    x = x.view(-1, self.input_dim).to(self.device)
    result = self.encoder(x)
    mu = self.enc_mu(result)
    log_var = self.enc_var(result)

    return Normal(mu, torch.exp(0.5 * log_var))
```

In other words, we encode first to a `128`-sized layer, and we use this to output the mean and the log-variance of the Normal distribution that parametrizes the latent variables. This distribution is a `Normal`, which is a class inside `torch.distributions`. Something similar can be done with the decoder:

```python
# Going from the latent dim to one-hot space.
self.decoder = nn.Sequential(
    nn.Linear(self.z_dim, 256),
    nn.Tanh(),
    nn.Linear(256, 512),
    nn.Tanh(),
    nn.Linear(512, self.input_dim),
).to(self.device)
```

using the `Categorical` distribution inside `torch`:
```python
def decode(self, z: t.Tensor) -> Categorical:
    # Returns p(x | z) = Cat(logits=what the decoder network says)
    logits = self.decoder(z)
    p_x_given_z = Categorical(
        logits=logits.reshape(-1, self.h, self.w, self.n_sprites)
    )

    return p_x_given_z
```

Notice how this allows us to write the ELBO loss using only probabilistic terms:

```python
def elbo_loss_function(
    self, x: t.Tensor, q_z_given_x: Distribution, p_x_given_z: Distribution
) -> torch.Tensor:
    # transform data from one-hot to integers
    x_ = x.to(self.device).argmax(dim=1)  

    # Computing the reconstruction loss (i.e. neg log likelihood)
    rec_loss = -p_x_given_z.log_prob(x_).sum(dim=(1, 2))

    # Computing the KL divergence (self.p_z is a unit Normal)
    kld = kl_divergence(q_z_given_x, self.p_z).sum(dim=1)  # b

    return (rec_loss + kld).mean()
```

The upside of using `torch.distributions` is that you could change the distribution of your data with minimal changes to this error function. the `log_prob` method works as a multiclass cross-entropy loss function when `p_x_given_z` is the categorical, but it could easily have been a MSE loss if we had used the Normal distribution instead.

You can find the entire description of the model [here](https://github.com/miguelgondu/minimal_VAE_on_Mario/blob/main/vae.py). In the repo, you can find an already-trained model under `./models/example.pt`. If you wanna see the entire latent space, take a look at [this image](/assets/massive_latent_space_2D.png).

<Heading aria-label="Jump to the simulator" as="h2" hash="TheSimulator">The simulator: the Mario AI competition</Heading>

In 2009, Robin Baumgarten's won the Mario AI competition with a super-human agent based on the A star algorithm.[^1] A modified version of the simulator used for the competition is available in [the MarioGAN repository](https://github.com/CIGbalance/DagstuhlGAN). This simulator gives you access to some statistics from the agent's runs. We did a small modification to extract the data as JSONs and then compiled it. This compiled version can be found in the repository as `simulator.jar`. We used OpenJDK version 15.0.2 to run our experiments.

The class `geometry.PlayLevel` inside `simulator.jar` lets you play a given level (given as a command-line argument) using your keyboard and mouse, and `geometry.EvalLevel` uses Baumgarten's A star agent to simulate the level and give you back telemetrics as JSON. This telemetrics count how much of the level was traversed, for how long, how many jumps were performed... [The entire description can be found here](https://github.com/miguelgondu/MarioGAN/blob/f6c32d6c9bc81da9d69b7d866caaa28a19a8f8b2/marioaiDagstuhl/src/ch/idsia/tools/EvaluationInfo.java#L86).

In the repo, you can find the simulator and a Python interface (in `simulator.py`). This script implements utilities for sending levels decoded from the latent space of the example network I provide. First, it implements a `run_level` script that swallows and runs a level using the simulator:

```python
def run_level(
    level: str,
    human_player: bool = False,
    max_time: int = 30,
    visualize: bool = False,
) -> dict:
    filepath = Path(__file__).parent.resolve()
    JARFILE_PATH = f"{filepath}/simulator.jar"
  
    # Run the simulator.jar file with the given level

    if human_player:
        # either lettting a human play it
        java = subprocess.Popen(
            ["java", "-cp", JARFILE_PATH, "geometry.PlayLevel", level],
            stdout=subprocess.PIPE,
        )
    else:
        # Or running it with the A* agent.
        java = subprocess.Popen(
            [
                "java",
                "-cp",
                JARFILE_PATH,
                "geometry.EvalLevel",
                level,
                str(max_time),
                str(visualize).lower(),
            ],
            stdout=subprocess.PIPE,
        )

    # It then reads the output and loads it
    # using JSON.
    lines = java.stdout.readlines()
    res = lines[-1]
    res = json.loads(res.decode("utf8"))
    res["level"] = level

    return res
```

To pass a level directly from latent space, we also implement a `test_level_from_z` method that decodes a level using a VAE, and then sends it to this `run_level` function. Every time you run `simulator.py`, the main function creates a random latent code `z` and runs it through the example network that's already in the network.


[^1]: If you want to learn more about the competition, read the paper! [Here's a link to a ResearchGate's post with the paper.](https://www.researchgate.net/publication/224177833_The_2009_Mario_AI_Competition)
